{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Virtual KITTI Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "annotation_folder = r'C:\\Arbeitsordner\\Abgaben_repo\\vkitti_2.0.3_textgt\\Scene01\\30-deg-right'\n",
    "data_folder = r'C:\\Arbeitsordner\\Abgaben_repo\\vkitti_2.0.3_rgb\\Scene01\\30-deg-right\\frames\\rgb\\Camera_0'\n",
    "\n",
    "pose_df = pd.read_csv(os.path.join(annotation_folder, 'pose.txt'), delim_whitespace=True)\n",
    "info_df = pd.read_csv(os.path.join(annotation_folder, 'info.txt'), delim_whitespace=True)\n",
    "bbox_df = pd.read_csv(os.path.join(annotation_folder, 'bbox.txt'), delim_whitespace=True)\n",
    "colors_df = pd.read_csv(os.path.join(annotation_folder, 'colors.txt'), delim_whitespace=True)\n",
    "intrinsic_df = pd.read_csv(os.path.join(annotation_folder, 'intrinsic.txt'), delim_whitespace=True)\n",
    "extrinsic_df = pd.read_csv(os.path.join(annotation_folder, 'extrinsic.txt'), delim_whitespace=True)\n",
    "\n",
    "# mapping dictionary from labels to colors\n",
    "label_to_color = {}\n",
    "for _, row in colors_df.iterrows():\n",
    "    label_to_color[row['Category']] = (row['r'], row['g'], row['b'])\n",
    "    print(label_to_color)\n",
    "\n",
    "# preprocess images\n",
    "def preprocess_image(image, target_size=(224, 224)):\n",
    "    image = cv2.resize(image, target_size)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = image.astype(np.float32) / 255.0\n",
    "    return image\n",
    "\n",
    "# Match RGB images to labels and 3D bounding boxes\n",
    "def match_data(rgb_folder, pose_df, info_df, bbox_df, label_to_color):\n",
    "    data = []\n",
    "    for root, dirs, files in os.walk(rgb_folder):\n",
    "        for file in files:\n",
    "            if file.endswith('.jpg'): \n",
    "\n",
    "                frame_id = file.split('_')[1]\n",
    "                frame_id = int(frame_id.split('.')[0])\n",
    "                \n",
    "                # Filter the bounding boxes for the current frame\n",
    "                frame_bbox = bbox_df[bbox_df['frame'] == frame_id]\n",
    "                print(frame_bbox)\n",
    "                \n",
    "                camera_id = 0 if 'Camera_0' in file else 1\n",
    "                \n",
    "                # Get the intrinsic parameters for the current camera\n",
    "                intrinsic_params = intrinsic_df[(intrinsic_df['frame'] == frame_id) & (intrinsic_df['cameraID'] == camera_id)]\n",
    "                K = intrinsic_params[['K[0,0]', 'K[1,1]', 'K[0,2]', 'K[1,2]']].values[0]\n",
    "                \n",
    "                # Get the extrinsic parameters for the current camera\n",
    "                extrinsic_params = extrinsic_df[(extrinsic_df['frame'] == frame_id) & (extrinsic_df['cameraID'] == camera_id)]\n",
    "                R = extrinsic_params[['r1,1', 'r1,2', 'r1,3', 'r2,1', 'r2,2', 'r2,3', 'r3,1', 'r3,2', 'r3,3']].values.reshape(3, 3)\n",
    "                t = extrinsic_params[['t1', 't2', 't3']].values\n",
    "                \n",
    "             \n",
    "                image_path = os.path.join(root, file)\n",
    "                image = cv2.imread(image_path)\n",
    "                \n",
    "                # check how to get the correct label for the bounding boxes in each image? What file to use to get the labels?\n",
    "                for idx, row in frame_bbox.iterrows():\n",
    "                    track_id = row['trackID']\n",
    "                    label_info = info_df[info_df['trackID'] == track_id]\n",
    "                    label = label_info['label'].values[0]\n",
    "                    \n",
    "                    color = label_to_color.get(label, (255, 255, 255))  \n",
    "                    \n",
    "                   \n",
    "                    \n",
    "                    data.append({'image': preprocess_image(roi), 'label': label, 'color': color, 'bbox': [obj_left, obj_top, obj_right, obj_bottom]})\n",
    "                    \n",
    "    return data\n",
    "\n",
    "data = match_data(annotation_folder, pose_df, info_df, bbox_df, label_to_color)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading image from: C:\\Arbeitsordner\\Abgaben_repo\\vkitti_2.0.3_rgb\\Scene02\\15-deg-right\\frames\\rgb\\Camera_0\\rgb_trackID.jpg\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Image not found at path: C:\\Arbeitsordner\\Abgaben_repo\\vkitti_2.0.3_rgb\\Scene02\\15-deg-right\\frames\\rgb\\Camera_0\\rgb_trackID.jpg",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [21], line 73\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# Try to access a single data point\u001b[39;00m\n\u001b[0;32m     72\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m  \u001b[38;5;66;03m# Replace with the index you want to check\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m image, bbox, label \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_single_data_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, image\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBounding box:\u001b[39m\u001b[38;5;124m\"\u001b[39m, bbox)\n",
      "Cell \u001b[1;32mIn [21], line 57\u001b[0m, in \u001b[0;36mVKittiDataset.get_single_data_point\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     55\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(img_path)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m image \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 57\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage not found at path: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     58\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(image, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_size)\n\u001b[0;32m     59\u001b[0m image \u001b[38;5;241m=\u001b[39m image \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m  \u001b[38;5;66;03m# Normalize image\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Image not found at path: C:\\Arbeitsordner\\Abgaben_repo\\vkitti_2.0.3_rgb\\Scene02\\15-deg-right\\frames\\rgb\\Camera_0\\rgb_trackID.jpg"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "class VKittiDataset(tf.keras.utils.Sequence):\n",
    "    def __init__(self, annotations_file, img_dir, batch_size=32, img_size=(375, 1242), shuffle=True):\n",
    "        self.annotations = pd.read_csv(annotations_file, sep=\" \", names=[\n",
    "            'frame', 'tid', 'label', 'truncated', 'occluded', 'alpha', 'l', 't', 'r', 'b',\n",
    "            'w3d', 'h3d', 'l3d', 'x3d', 'y3d', 'z3d', 'ry', 'rx', 'rz', 'truncr', 'occupr', \n",
    "            'orig_label', 'moving', 'model', 'color'])\n",
    "        self.img_dir = img_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.annotations) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        indices = self.indices[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        batch_annotations = [self.annotations.iloc[i] for i in indices]\n",
    "        X, bbox_y, label_y = self.__data_generation(batch_annotations)\n",
    "        return X, {'bbox_output': bbox_y, 'label_output': label_y}\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self.indices = np.arange(len(self.annotations))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "    \n",
    "    def __data_generation(self, batch_annotations):\n",
    "        X = np.empty((self.batch_size, *self.img_size, 3))\n",
    "        bbox_y = np.empty((self.batch_size, 7))  # 7 values for 3D bounding box\n",
    "        label_y = np.empty((self.batch_size, 1))  # 1 value for object label\n",
    "        \n",
    "        for i, ann in enumerate(batch_annotations):\n",
    "            img_path = os.path.join(self.img_dir, f\"rgb_{str(ann['frame']).zfill(5)}.jpg\")\n",
    "            image = cv2.imread(img_path)\n",
    "            if image is None:\n",
    "                raise FileNotFoundError(f\"Image not found at path: {img_path}\")\n",
    "            image = cv2.resize(image, self.img_size)\n",
    "            X[i,] = image / 255.0  # Normalize image\n",
    "            bbox_y[i,] = ann[['x3d', 'y3d', 'z3d', 'w3d', 'h3d', 'l3d', 'ry']].to_numpy()\n",
    "            label_y[i,] = ann['label']  # Assuming the label column contains the object class\n",
    "            \n",
    "        return X, bbox_y, label_y\n",
    "\n",
    "    def get_single_data_point(self, index):\n",
    "        ann = self.annotations.iloc[index]\n",
    "        img_path = os.path.join(self.img_dir, f\"rgb_{str(ann['frame']).zfill(5)}.jpg\")\n",
    "        print(f\"Loading image from: {img_path}\")  # Print the image path\n",
    "        image = cv2.imread(img_path)\n",
    "        if image is None:\n",
    "            raise FileNotFoundError(f\"Image not found at path: {img_path}\")\n",
    "        image = cv2.resize(image, self.img_size)\n",
    "        image = image / 255.0  # Normalize image\n",
    "        bbox = ann[['x3d', 'y3d', 'z3d', 'w3d', 'h3d', 'l3d', 'ry']].to_numpy()\n",
    "        label = ann['label']  # Assuming the label column contains the object class\n",
    "        return image, bbox, label\n",
    "\n",
    "\n",
    "# Specify the correct paths\n",
    "annotations_file = r\"C:\\Arbeitsordner\\Abgaben_repo\\vkitti_2.0.3_textgt\\Scene02\\15-deg-right\\info.txt\"\n",
    "img_dir = r\"C:\\Arbeitsordner\\Abgaben_repo\\vkitti_2.0.3_rgb\\Scene02\\15-deg-right\\frames\\rgb\\Camera_0\"\n",
    "\n",
    "train_dataset = VKittiDataset(annotations_file=annotations_file, img_dir=img_dir, batch_size=4)\n",
    "\n",
    "# Try to access a single data point\n",
    "index = 0  # Replace with the index you want to check\n",
    "image, bbox, label = train_dataset.get_single_data_point(index)\n",
    "\n",
    "print(\"Image shape:\", image.shape)\n",
    "print(\"Bounding box:\", bbox)\n",
    "print(\"Label:\", label)\n",
    "\n",
    "# Display the image (optional)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.title(f\"Label: {label}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KITTI Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "\n",
    "def load_data(image_dir, label_dir):\n",
    "    data = []\n",
    "    image_files = sorted(os.listdir(image_dir))\n",
    "    \n",
    "    for image_file in image_files:\n",
    "        if image_file.endswith('.png'):\n",
    "            image_path = os.path.join(image_dir, image_file)\n",
    "            label_path = os.path.join(label_dir, image_file[:-4] + \".txt\")\n",
    "            if os.path.isfile(label_path):\n",
    "                labels = parse_label(label_path)\n",
    "                data.append({\n",
    "                    \"image_path\": image_path,\n",
    "                    \"labels\": labels\n",
    "                })\n",
    "    return data\n",
    "\n",
    "def parse_label(label_file):\n",
    "    with open(label_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    labels = []\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        label_info = line.split(' ')\n",
    "        if label_info[0] in ['Car', 'Truck', 'Pedestrian', 'Cyclist']:\n",
    "            label = {\n",
    "                \"type\": label_info[0],\n",
    "                \"truncated\": float(label_info[1]),\n",
    "                \"occluded\": int(label_info[2]),\n",
    "                \"alpha\": float(label_info[3]),\n",
    "                \"bbox\": [float(x) for x in label_info[4:8]],\n",
    "                \"dimensions\": [float(x) for x in label_info[8:11]],\n",
    "                \"location\": [float(x) for x in label_info[11:14]],\n",
    "                \"rotation_y\": float(label_info[14]),\n",
    "                \"score\": float(label_info[15]) if len(label_info) > 15 else None\n",
    "            }\n",
    "            labels.append(label)\n",
    "\n",
    "    return labels\n",
    "\n",
    "def visualize_data(data):\n",
    "    for entry in data:\n",
    "        image_path = entry[\"image_path\"]\n",
    "        labels = entry[\"labels\"]\n",
    "        image = cv2.imread(image_path)\n",
    "        \n",
    "        # Plot the image\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Plot bounding boxes\n",
    "        for label in labels:\n",
    "            bbox = label[\"bbox\"]\n",
    "            cv2.rectangle(image, (int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3])), (0, 255, 0), 2)\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "\n",
    "image_dir = r\"C:\\Arbeitsordner\\Abgaben_repo\\Datasets\\KITTI\\data_object_image_3\\training\\image_3\"\n",
    "label_dir = r\"C:\\Arbeitsordner\\Abgaben_repo\\Datasets\\KITTI\\data_object_label_2\\training\\label_2\"\n",
    "data = load_data(image_dir, label_dir)\n",
    "# visualize_data(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class MeanAveragePrecision(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, num_classes, **kwargs):\n",
    "        super(MeanAveragePrecision, self).__init__(**kwargs)\n",
    "        self.num_classes = num_classes\n",
    "        self.mAP = tf.Variable(0.0, trainable=False)\n",
    "        self.total_samples = tf.Variable(0, trainable=False)\n",
    "        self.total_iou = tf.Variable([0.0] * num_classes, trainable=False)\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        bbox_true, label_true = y_true\n",
    "        bbox_pred, label_pred = y_pred\n",
    "\n",
    "        batch_size = tf.shape(bbox_true)[0]\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            bboxes_true = bbox_true[i]\n",
    "            bboxes_pred = bbox_pred[i]\n",
    "            labels_true = label_true[i]\n",
    "            labels_pred = label_pred[i]\n",
    "\n",
    "            # Calculate IoU for all true and predicted boxes\n",
    "            iou = calculate_iou(tf.reshape(bboxes_true, (-1, 4)), tf.reshape(bboxes_pred, (-1, 4)))\n",
    "\n",
    "            # Compute mAP for each class\n",
    "            for cls in range(self.num_classes):\n",
    "                true_cls_mask = tf.cast(tf.equal(labels_true, cls), dtype=tf.float32)\n",
    "                pred_cls_mask = tf.cast(tf.equal(labels_pred, cls), dtype=tf.float32)\n",
    "\n",
    "                true_positives = tf.reduce_sum(true_cls_mask * pred_cls_mask)\n",
    "                false_positives = tf.reduce_sum((1 - true_cls_mask) * pred_cls_mask)\n",
    "                false_negatives = tf.reduce_sum(true_cls_mask * (1 - pred_cls_mask))\n",
    "\n",
    "                precision = true_positives / (true_positives + false_positives)\n",
    "                recall = true_positives / (true_positives + false_negatives)\n",
    "\n",
    "                average_precision = tf.cond(tf.equal(true_positives + false_positives, 0),\n",
    "                                            lambda: tf.constant(0.0),\n",
    "                                            lambda: precision * recall)\n",
    "\n",
    "                self.total_iou[cls].assign_add(tf.reduce_sum(iou * true_cls_mask))\n",
    "                self.mAP.assign_add(average_precision)\n",
    "                self.total_samples.assign_add(1)\n",
    "\n",
    "    def result(self):\n",
    "        return tf.math.divide_no_nan(self.mAP, self.total_samples)\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.mAP.assign(0.0)\n",
    "        self.total_samples.assign(0)\n",
    "        self.total_iou.assign([0.0] * self.num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: Tensor(\"Pad:0\", shape=(None, None, 4), dtype=float32) Tensor(\"Pad_1:0\", shape=(None, None), dtype=int32)\n",
      "<MapDataset shapes: ((None, 224, 224, 3), (None, None, 4), (None, None)), types: (tf.float32, tf.float32, tf.int32)>\n",
      "Image shape: (1, 224, 224, 3)\n",
      "Bounding box shapes: tf.Tensor(\n",
      "[[[0.40194666 0.398438   0.5124533  0.4485185 ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]]], shape=(1, 10, 4), dtype=float32)\n",
      "Labels: tf.Tensor([[0 0 0 0 0 0 0 0 0 0]], shape=(1, 10), dtype=int32)\n",
      "Number of objects: 10\n",
      "--------------------------------------------------\n",
      "Image shape: (1, 224, 224, 3)\n",
      "Bounding box shapes: tf.Tensor(\n",
      "[[[0.48171124 0.44008884 0.5474599  0.46107432]\n",
      "  [0.4289305  0.36235055 0.55342245 0.44479805]\n",
      "  [0.3255615  0.         0.4909893  0.07074314]\n",
      "  [0.45467913 0.2655008  0.5442781  0.3208966 ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]]], shape=(1, 10, 4), dtype=float32)\n",
      "Labels: tf.Tensor([[0 0 0 0 0 0 0 0 0 0]], shape=(1, 10), dtype=int32)\n",
      "Number of objects: 10\n",
      "--------------------------------------------------\n",
      "Image shape: (1, 224, 224, 3)\n",
      "Bounding box shapes: tf.Tensor(\n",
      "[[[0.45608    0.4747504  0.56608    0.5102818 ]\n",
      "  [0.38408    0.18252818 0.49285334 0.26083735]\n",
      "  [0.45437333 0.35171497 0.51256    0.37911433]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]]], shape=(1, 10, 4), dtype=float32)\n",
      "Labels: tf.Tensor([[2 0 0 0 0 0 0 0 0 0]], shape=(1, 10), dtype=int32)\n",
      "Number of objects: 10\n",
      "--------------------------------------------------\n",
      "Image shape: (1, 224, 224, 3)\n",
      "Bounding box shapes: tf.Tensor(\n",
      "[[[0.45496    0.47175524 0.52218664 0.49735105]\n",
      "  [0.46968    0.42884862 0.53056    0.45258453]\n",
      "  [0.48976    0.48506442 0.56608    0.5018921 ]\n",
      "  [0.38549334 0.00508857 0.52592    0.11424316]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]]], shape=(1, 10, 4), dtype=float32)\n",
      "Labels: tf.Tensor([[0 0 1 0 0 0 0 0 0 0]], shape=(1, 10), dtype=int32)\n",
      "Number of objects: 10\n",
      "--------------------------------------------------\n",
      "Image shape: (1, 224, 224, 3)\n",
      "Bounding box shapes: tf.Tensor(\n",
      "[[[0.03466666 0.8287762  0.71152    0.99919486]\n",
      "  [0.40018666 0.6329066  0.5728267  0.65697265]\n",
      "  [0.42765334 0.6545491  0.5579467  0.6709662 ]\n",
      "  [0.42906666 0.6720209  0.5594133  0.6861353 ]\n",
      "  [0.43162668 0.6678744  0.5070933  0.6841868 ]\n",
      "  [0.45792    0.5897665  0.54506665 0.5994927 ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]]], shape=(1, 10, 4), dtype=float32)\n",
      "Labels: tf.Tensor([[5 5 3 3 7 5 0 0 0 0]], shape=(1, 10), dtype=int32)\n",
      "Number of objects: 10\n",
      "--------------------------------------------------\n",
      "B: KerasTensor(type_spec=TensorSpec(shape=(None, 10, 4), dtype=tf.float32, name=None), name='bbox_output_2/Reshape:0', description=\"created by layer 'bbox_output_2'\") l: KerasTensor(type_spec=TensorSpec(shape=(None, 10, 4), dtype=tf.float32, name=None), name='label_output_reshape/Reshape:0', description=\"created by layer 'label_output_reshape'\")\n",
      "Epoch 1/5\n",
      "  8/317 [..............................] - ETA: 3:22 - loss: 1.0368 - bbox_output_2_loss: 0.5643 - label_output_reshape_loss: 1.5093 - bbox_output_2_mse: 0.8889 - label_output_reshape_categorical_accuracy: 0.3000     "
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " Incompatible shapes: [1,10,4] vs. [1,11,4]\n\t [[node gradient_tape/mean_squared_error/BroadcastGradientArgs\n (defined at C:\\Users\\elisa\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:464)\n]] [Op:__inference_train_function_205627]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node gradient_tape/mean_squared_error/BroadcastGradientArgs:\nIn[0] gradient_tape/mean_squared_error/Shape_4:\t\nIn[1] gradient_tape/mean_squared_error/Shape_5:\n\nOperation defined at: (most recent call last)\n>>>   File \"c:\\Users\\elisa\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 197, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"c:\\Users\\elisa\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"C:\\Users\\elisa\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"C:\\Users\\elisa\\AppData\\Roaming\\Python\\Python39\\site-packages\\traitlets\\config\\application.py\", line 982, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"C:\\Users\\elisa\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"C:\\Users\\elisa\\AppData\\Roaming\\Python\\Python39\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"c:\\Users\\elisa\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"c:\\Users\\elisa\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"c:\\Users\\elisa\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\events.py\", line 80, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"C:\\Users\\elisa\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"C:\\Users\\elisa\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n>>>     await dispatch(*args)\n>>> \n>>>   File \"C:\\Users\\elisa\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n>>>     await result\n>>> \n>>>   File \"C:\\Users\\elisa\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n>>>     reply_content = await reply_content\n>>> \n>>>   File \"C:\\Users\\elisa\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n>>>     res = shell.run_cell(\n>>> \n>>>   File \"C:\\Users\\elisa\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n>>>     return super().run_cell(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\elisa\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 2940, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"C:\\Users\\elisa\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 2995, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"C:\\Users\\elisa\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"C:\\Users\\elisa\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3194, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"C:\\Users\\elisa\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3373, in run_ast_nodes\n>>>     if await self.run_code(code, result, async_=asy):\n>>> \n>>>   File \"C:\\Users\\elisa\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3433, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"C:\\Users\\elisa\\AppData\\Local\\Temp\\ipykernel_24680\\2422717117.py\", line 129, in <module>\n>>>     main()\n>>> \n>>>   File \"C:\\Users\\elisa\\AppData\\Local\\Temp\\ipykernel_24680\\2422717117.py\", line 126, in main\n>>>     model.fit(train_dataset, epochs=5, batch_size=1) #, callbacks=[mAP_metric])\n>>> \n>>>   File \"C:\\Users\\elisa\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\elisa\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"C:\\Users\\elisa\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"C:\\Users\\elisa\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"C:\\Users\\elisa\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"C:\\Users\\elisa\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 816, in train_step\n>>>     self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n>>> \n>>>   File \"C:\\Users\\elisa\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 530, in minimize\n>>>     grads_and_vars = self._compute_gradients(\n>>> \n>>>   File \"C:\\Users\\elisa\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 583, in _compute_gradients\n>>>     grads_and_vars = self._get_gradients(tape, loss, var_list, grad_loss)\n>>> \n>>>   File \"C:\\Users\\elisa\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 464, in _get_gradients\n>>>     grads = tape.gradient(loss, var_list, grad_loss)\n>>> ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [19], line 129\u001b[0m\n\u001b[0;32m    126\u001b[0m     model\u001b[38;5;241m.\u001b[39mfit(train_dataset, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m#, callbacks=[mAP_metric])\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 129\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [19], line 126\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    112\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m    113\u001b[0m     loss\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m    114\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbbox_output_2\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean_squared_error\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    119\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam()\n\u001b[0;32m    120\u001b[0m )\n\u001b[0;32m    122\u001b[0m \u001b[38;5;66;03m# Define custom metric for mAP\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m#mAP_metric = MeanAveragePrecision(num_classes=num_classes)\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \n\u001b[0;32m    125\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m--> 126\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py:58\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     57\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 58\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     59\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     61\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m:  Incompatible shapes: [1,10,4] vs. [1,11,4]\n\t [[node gradient_tape/mean_squared_error/BroadcastGradientArgs\n (defined at C:\\Users\\elisa\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:464)\n]] [Op:__inference_train_function_205627]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node gradient_tape/mean_squared_error/BroadcastGradientArgs:\nIn[0] gradient_tape/mean_squared_error/Shape_4:\t\nIn[1] gradient_tape/mean_squared_error/Shape_5:\n\nOperation defined at: (most recent call last)\n>>>   File \"c:\\Users\\elisa\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 197, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"c:\\Users\\elisa\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"C:\\Users\\elisa\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"C:\\Users\\elisa\\AppData\\Roaming\\Python\\Python39\\site-packages\\traitlets\\config\\application.py\", line 982, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"C:\\Users\\elisa\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"C:\\Users\\elisa\\AppData\\Roaming\\Python\\Python39\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"c:\\Users\\elisa\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"c:\\Users\\elisa\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"c:\\Users\\elisa\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\events.py\", line 80, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"C:\\Users\\elisa\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"C:\\Users\\elisa\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n>>>     await dispatch(*args)\n>>> \n>>>   File \"C:\\Users\\elisa\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n>>>     await result\n>>> \n>>>   File \"C:\\Users\\elisa\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n>>>     reply_content = await reply_content\n>>> \n>>>   File \"C:\\Users\\elisa\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n>>>     res = shell.run_cell(\n>>> \n>>>   File \"C:\\Users\\elisa\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n>>>     return super().run_cell(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\elisa\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 2940, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"C:\\Users\\elisa\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 2995, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"C:\\Users\\elisa\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"C:\\Users\\elisa\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3194, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"C:\\Users\\elisa\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3373, in run_ast_nodes\n>>>     if await self.run_code(code, result, async_=asy):\n>>> \n>>>   File \"C:\\Users\\elisa\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3433, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"C:\\Users\\elisa\\AppData\\Local\\Temp\\ipykernel_24680\\2422717117.py\", line 129, in <module>\n>>>     main()\n>>> \n>>>   File \"C:\\Users\\elisa\\AppData\\Local\\Temp\\ipykernel_24680\\2422717117.py\", line 126, in main\n>>>     model.fit(train_dataset, epochs=5, batch_size=1) #, callbacks=[mAP_metric])\n>>> \n>>>   File \"C:\\Users\\elisa\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\elisa\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"C:\\Users\\elisa\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"C:\\Users\\elisa\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"C:\\Users\\elisa\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"C:\\Users\\elisa\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 816, in train_step\n>>>     self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n>>> \n>>>   File \"C:\\Users\\elisa\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 530, in minimize\n>>>     grads_and_vars = self._compute_gradients(\n>>> \n>>>   File \"C:\\Users\\elisa\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 583, in _compute_gradients\n>>>     grads_and_vars = self._get_gradients(tape, loss, var_list, grad_loss)\n>>> \n>>>   File \"C:\\Users\\elisa\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 464, in _get_gradients\n>>>     grads = tape.gradient(loss, var_list, grad_loss)\n>>> "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_image(image, bbox, label, input_shape, max_objects):\n",
    "    max_objects = max_objects\n",
    "    # Resize image\n",
    "    image = tf.image.resize(image, (input_shape[0], input_shape[1]))\n",
    "    # Normalize image\n",
    "    image = image / 255.0  # Assuming input range [0, 255]\n",
    "    \n",
    "    \n",
    "    \n",
    "    # One-hot encode the labels\n",
    "    label = tf.cast(label, tf.int32)\n",
    "    \n",
    "    # Pad the bounding boxes and labels to the max_objects\n",
    "    bbox_padding = tf.maximum(max_objects - tf.shape(bbox)[1], 0)\n",
    "    label_padding = tf.maximum(max_objects - tf.shape(label)[1], 0)\n",
    "    bbox = tf.pad(bbox, [[0, 0], [0, bbox_padding], [0, 0]])\n",
    "    label = tf.pad(label, [[0, 0], [0, label_padding]])\n",
    "    print(\"test:\", bbox, label)\n",
    "    return image, bbox, label\n",
    "\n",
    "\n",
    "\n",
    "def load_kitti_dataset(input_shape, max_objects):\n",
    "    dataset = tfds.load('kitti', split='train[:5%]')\n",
    "    train_dataset = dataset.batch(1) #['train']\n",
    "    #test_dataset = dataset['test']\n",
    "\n",
    "    # Preprocess dataset\n",
    "    #train_dataset = train_dataset.map(lambda image, bbox, label: (image, bbox, label, tf.reduce_sum(label, axis=-1)))\n",
    "    train_dataset = train_dataset.map(lambda x: preprocess_image(x['image'], x['objects']['bbox'], x['objects']['type'], input_shape, max_objects))\n",
    "    #test_dataset = test_dataset.map(lambda x: preprocess_image(x['image'], x['objects']['bbox'], x['objects']['type'], input_shape))\n",
    "    print(train_dataset)\n",
    "    return train_dataset #, test_dataset\n",
    "\n",
    "\n",
    "def create_model(input_shape, max_objects, num_classes):\n",
    "    # Define input layer\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "    # Feature extraction backbone (e.g., CNN)\n",
    "    backbone = tf.keras.applications.ResNet50(\n",
    "        include_top=False, weights='imagenet', input_tensor=inputs\n",
    "    )\n",
    "\n",
    "    # Additional layers for feature fusion\n",
    "    x = backbone.output\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    label_output = layers.Dense(max_objects * 4, activation='softmax', name='label_output')(x)\n",
    "    label_output = layers.Reshape((max_objects, 4), name='label_output_reshape')(label_output)\n",
    "\n",
    "    # Output head for bounding box regression\n",
    "    bbox_output = layers.Dense(4 * max_objects, name='bbox_output')(x)  # Output shape: (None, 4 * max_objects)\n",
    "    bbox_output = layers.Reshape((max_objects, 4), name='bbox_output_2')(bbox_output)\n",
    "    print(\"B:\", bbox_output, \"l:\", label_output)\n",
    "\n",
    "    # Define the model\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=[bbox_output, label_output])\n",
    "    \n",
    "\n",
    "    return model\n",
    "\n",
    "def calculate_iou(boxes1, boxes2):\n",
    "    # Calculate Intersection over Union (IoU) for two sets of bounding boxes\n",
    "    boxes1 = tf.expand_dims(boxes1, -2)\n",
    "    boxes2 = tf.expand_dims(boxes2, 0)\n",
    "\n",
    "    # Calculate intersection areas\n",
    "    intersect_mins = tf.maximum(boxes1[..., :2], boxes2[..., :2])\n",
    "    intersect_maxes = tf.minimum(boxes1[..., 2:], boxes2[..., 2:])\n",
    "    intersect_wh = tf.maximum(intersect_maxes - intersect_mins, 0.0)\n",
    "    intersect_area = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "\n",
    "    # Calculate box areas\n",
    "    boxes1_area = (boxes1[..., 2] - boxes1[..., 0]) * (boxes1[..., 3] - boxes1[..., 1])\n",
    "    boxes2_area = (boxes2[..., 2] - boxes2[..., 0]) * (boxes2[..., 3] - boxes2[..., 1])\n",
    "\n",
    "    # Calculate union area\n",
    "    union_area = boxes1_area + boxes2_area - intersect_area\n",
    "\n",
    "    # Calculate IoU\n",
    "    iou = intersect_area / union_area\n",
    "\n",
    "    return iou\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Define input shape and number of classes\n",
    "    input_shape = (224, 224, 3)  # Example input shape\n",
    "    num_classes = 8  # Example number of classes\n",
    "    max_objects = 10  # Example maximum number of objects\n",
    "    \n",
    "    # Load and preprocess KITTI dataset\n",
    "    train_dataset = load_kitti_dataset(input_shape, max_objects)\n",
    "    for image, bbox, label in train_dataset.take(5):  # Print the first 5 samples\n",
    "        print(\"Image shape:\", image.shape)\n",
    "        print(\"Bounding box shapes:\", bbox)\n",
    "        print(\"Labels:\", label)\n",
    "        print(\"Number of objects:\", tf.shape(bbox)[1].numpy())  # Number of objects in the image\n",
    "        print(\"-\" * 50) \n",
    "       \n",
    "    # Define and compile the model\n",
    "    model = create_model(input_shape=input_shape, max_objects=max_objects, num_classes=num_classes)\n",
    "    model.compile(\n",
    "        loss={\n",
    "            'bbox_output_2': \"mean_squared_error\",\n",
    "            'label_output_reshape': tf.keras.losses.CategoricalCrossentropy()\n",
    "        },\n",
    "        loss_weights={'bbox_output_2': 0.5, 'label_output_reshape': 0.5},\n",
    "        metrics={'bbox_output_2': 'mse', 'label_output_reshape': 'categorical_accuracy'},\n",
    "        optimizer=tf.keras.optimizers.Adam()\n",
    "    )\n",
    "    \n",
    "    # Define custom metric for mAP\n",
    "    #mAP_metric = MeanAveragePrecision(num_classes=num_classes)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(train_dataset, epochs=5, batch_size=1) #, callbacks=[mAP_metric])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m5\u001b[39m):  \u001b[38;5;66;03m# Print the first 5 samples\u001b[39;00m\n\u001b[0;32m      2\u001b[0m     image, bbox, label \u001b[38;5;241m=\u001b[39m sample\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, image\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "for sample in train_dataset.take(5):  # Print the first 5 samples\n",
    "    image, bbox, label = sample\n",
    "    print(\"Image shape:\", image.shape)\n",
    "    print(\"Bounding box shape:\", bbox.shape)\n",
    "    print(\"Label shape:\", label.shape)\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting h5py\n",
      "  Downloading h5py-3.11.0-cp39-cp39-win_amd64.whl (3.0 MB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\elisa\\appdata\\roaming\\python\\python39\\site-packages (from h5py) (1.23.5)\n",
      "Installing collected packages: h5py\n",
      "Successfully installed h5py-3.11.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.7.4 requires wheel<1.0,>=0.32.0, which is not installed.\n",
      "tensorcross 0.4.3 requires scikit-learn, which is not installed.\n",
      "WARNING: You are using pip version 21.1.1; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\elisa\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wrapt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_model\u001b[39m(input_shape):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\__init__.py:41\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msix\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_six\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LazyLoader \u001b[38;5;28;01mas\u001b[39;00m _LazyLoader\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\__init__.py:46\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m context\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Bring in subpackages.\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# from tensorflow.python import keras\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\data\\__init__.py:25\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m print_function\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m experimental\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AUTOTUNE\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\data\\experimental\\__init__.py:98\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m print_function\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[1;32m---> 98\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m service\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatching\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dense_to_ragged_batch\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatching\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dense_to_sparse_batch\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\data\\experimental\\service\\__init__.py:374\u001b[0m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m division\n\u001b[0;32m    372\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m print_function\n\u001b[1;32m--> 374\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_service_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_service_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m from_dataset_id\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_service_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m register_dataset\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\data_service_ops.py:27\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compat\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compression_ops\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservice\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _pywrap_server_lib\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservice\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _pywrap_utils\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\compression_ops.py:20\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m division\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m print_function\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m structure\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gen_experimental_dataset_ops \u001b[38;5;28;01mas\u001b[39;00m ged_ops\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompress\u001b[39m(element):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\data\\util\\structure.py:24\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msix\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwrapt\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nest\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m composite_tensor\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'wrapt'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "def create_model(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # Shared base network\n",
    "    x = Conv2D(16, (3, 3), activation='relu')(inputs)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(32, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    # Bounding box regression head\n",
    "    bbox_output = Dense(7, name='bbox_output')(x)  # 7 values: x3d, y3d, z3d, w3d, h3d, l3d, ry\n",
    "    \n",
    "    # Object classification head\n",
    "    label_output = Dense(1, activation='softmax', name='label_output')(x)  \n",
    "\n",
    "    model = Model(inputs=inputs, outputs=[bbox_output, label_output])\n",
    "    \n",
    "    return model\n",
    "\n",
    "input_shape = (375, 1242, 3)\n",
    "model = create_model(input_shape)\n",
    "model.compile(optimizer='adam', \n",
    "              loss={'bbox_output': 'mean_squared_error', 'label_output': 'sparse_categorical_crossentropy'},\n",
    "              metrics={'bbox_output': 'mse', 'label_output': 'accuracy'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.2-cp39-cp39-win_amd64.whl (11.6 MB)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\elisa\\appdata\\roaming\\python\\python39\\site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\elisa\\appdata\\roaming\\python\\python39\\site-packages (from pandas) (2.8.2)\n",
      "Collecting tzdata>=2022.7\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\elisa\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Installing collected packages: tzdata, pytz, pandas\n",
      "Successfully installed pandas-2.2.2 pytz-2024.1 tzdata-2024.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.1; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\elisa\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
